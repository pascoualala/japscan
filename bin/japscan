#!/usr/bin/env ruby

require 'nokogiri'
require 'open-uri'
require 'pathname'
require 'fileutils'

# Coding style is highly procedural,
# giving feed back as soon.

def main arguments

  $status = 0

  $command = 'japscan'
  $site = 'japscan.com'

  usage = <<-EOF.gsub /^ +/, ''
    Usage: #{$command} <uri> [destination]
    Where <uri> must match:
    – #{$site}/mangas/<manga>
    – #{$site}/lecture-en-ligne/<manga>/<token>
    Where <token> must match:
    – <volume>-<number>: volume
    – <number>: scan
    Pages are saved to <destination>/<manga>/<part>/<number>.cbz,
    using the comic book archive format.
    Default value of <destination> is japscan.com
  EOF

  uri, $destination = arguments

  if not uri
    STDERR.puts usage
    exit 1
  end

  $destination ||= ENV['JAPSCAN_DEFAULT_DESTINATION'] || $site

  $regex_manga = %r(#{$site}/mangas/([[:alnum:]-]+))
  $regex_part = %r(#{$site}/lecture-en-ligne/([[:alnum:]-]+)/(volume-)?([.0-9]+))

  case uri
  when $regex_manga
    get_manga $1
  when $regex_part
    manga = $1
    part = $2 ? 'volume' : 'scan'
    number = $3
    get_part manga, part, number
  else
    STDERR.puts usage
    exit 1
  end

  exit $status

end

def get_manga manga

  url = "http://#{$site}/mangas/#{manga}"

  document = Nokogiri::HTML open url

  document.search('#liste_chapitres ul li a').reverse_each do |node|
    manga, token, number = node['href'].match($regex_part).captures
    part = token ? 'volume' : 'scan'
    get_part manga, part, number
  end

end

def get_part manga, part, number

  # <destination>/<manga>/<part>/<number>/
  destination_directory = Pathname($destination) + manga + part + number

  archive = destination_directory.dirname + (destination_directory.basename.to_s + '.cbz')

  if archive.exist?
    puts ' ' + archive.to_s
    return
  end

  uri_part = part == 'volume' ? "volume-#{number}" : number
  url = "http://#{$site}/lecture-en-ligne/#{manga}/#{uri_part}"

  document = Nokogiri::HTML open url

  # Redirection
  # Examples
  # – http://japscan.com/lecture-en-ligne/one-punch-man/94.3/
  if not document.at('#pagination')
    $status = 1
    STDERR.puts <<-EOF.gsub /^ +/, ''
      Something went wrong
      URL: #{url}
      Error: Redirected
    EOF
    return
  end

  # Encrypted images
  if document.at('#parImg')
    $status = 1
    STDERR.puts <<-EOF.gsub /^ +/, ''
      Something went wrong
      URL: #{url}
      Error: Encrypted images
    EOF
    return
  end

  status_code =
  if destination_directory.exist?
    ' '
  else
    FileUtils.mkdir_p destination_directory
    ''
  end
  puts status_code + destination_directory.to_s + '/'

  # Pagination looks like:
  # ╭─────────────────────────────────────────────────────────────────────────╮
  # │#back_chapter #back_link 1 2 <ads> … 97 98 <ads> #next_link #next_chapter│
  # ╰─────────────────────────────────────────────────────────────────────────╯
  # Complement variable is used to pad pages with zeros.
  # Use case is when sort is alphabetical.
  # There is 2 ads, at the beginning and ending of scans.
  # As ads are skipped from the downloading, we use the variable ads count to adjust complement value.
  # For example: (101 pages, complement: 3) − (2 ads) → (99 pages, complement: 2)
  # That value is hard coded to avoid searching for ads before processing downloading.
  pages = document.search '#pagination ul li a:not(#back_chapter):not(#back_link):not(#next_link):not(#next_chapter)'

  if pages.empty?
    # Examples
    # – http://japscan.com/lecture-en-ligne/gosu/43/
    first_image_source = document.at('#images img')['src']
    complement = first_image_source.match(/([0-9]+)[.][a-z]+/).captures.first.length
    page_number = 1
    loop do
      page = "%0#{complement}d" % page_number
      extension = File.extname first_image_source
      source = File.dirname(first_image_source) + '/' + page + extension
      destination = destination_directory + (page + extension)
      if destination.exist?
        puts ' ' + destination.to_s
        page_number += 1
        next
      end
      # Exceptions
      begin
        download source, destination
      rescue Exception => error
        $status = 1
        STDERR.puts <<-EOF.gsub /^ +/, ''
          Something went wrong while downloading
          URL: #{url}
          Error: #{error.message}
          Source: #{source}
          Destination: #{destination}
        EOF
        destination.delete if destination.exist?
        puts '-' + destination.to_s
        break
      end
      puts destination
      page_number += 1
    end
  else
    last_page_number = pages.last['href'].match(/(\d+).html/).captures.first.to_i
    ads_count = 2
    complement = (last_page_number - ads_count).to_s.length
    page_number = 1
    (1..last_page_number).each do |index|
      page_url = "#{url}/#{index}.html"
      document = Nokogiri::HTML open page_url
      source = document.at('#image')['src']
      # Skip ads
      if source.match %r(/lels/)
        next
      end
      page = "%0#{complement}d" % page_number
      extension = File.extname source
      destination = destination_directory + (page + extension)
      if destination.exist?
        puts ' ' + destination.to_s
        page_number += 1
        next
      end
      # Exceptions
      begin
        download source, destination
      rescue Exception => error
        $status = 1
        STDERR.puts <<-EOF.gsub /^ +/, ''
          Something went wrong while downloading
          URL: #{page_url}
          Error: #{error.message}
          Source: #{source}
          Destination: #{destination}
        EOF
        destination.delete if destination.exist?
        puts '-' + destination.to_s
        next
      end
      puts destination
      page_number += 1
    end
  end

  success = system <<-EOF
    cd #{destination_directory.dirname}
    zip --recurse-paths #{archive.basename} #{destination_directory.basename}
  EOF

  if success
    puts archive
  else
    $status = 1
  end

  puts '-' + destination_directory.to_s + '/'
  FileUtils.rm_rf destination_directory

end

def download uri, path
  File.open(path, 'w') do |file|
    IO.copy_stream (open uri), file
  end
end

main ARGV
